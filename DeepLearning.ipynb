{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZnnv4wFxv7o",
        "outputId": "a00587b8-4305-48c4-8546-f632f14785cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Deep-learning Project/Kathbath-Bengali-Test-Known.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"‚úÖ Dataset extracted to:\", extract_path)\n",
        "print(\"üìÇ Files:\", os.listdir(extract_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwtYLBprzXws",
        "outputId": "c1d89a30-efbc-40df-d301-d7e3a724def3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Dataset extracted to: /content/dataset\n",
            "üìÇ Files: ['Kathbath-Bengali-Test-Known']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "DATA_PATH = \"/content/dataset/Kathbath-Bengali-Test-Known\"\n",
        "for root, dirs, files in os.walk(DATA_PATH):\n",
        "    print(f\"üìÅ {root} ‚Üí {len(files)} files, {len(dirs)} subfolders\")\n",
        "    if any(f.endswith('.json') or f.endswith('.csv') or f.endswith('.tsv') for f in files):\n",
        "        print(\"üóÉÔ∏è\", [f for f in files if f.endswith(('.json','.csv','.tsv'))][:5])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0n-L6Q3ztUA",
        "outputId": "72fc9959-ce95-4083-e249-28f8a7d82a7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ /content/dataset/Kathbath-Bengali-Test-Known ‚Üí 2 files, 1 subfolders\n",
            "üóÉÔ∏è ['data.json', 'params.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "json_path = \"/content/dataset/Kathbath-Bengali-Test-Known/data.json\"\n",
        "\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"üîπ Type of JSON:\", type(data))\n",
        "print(\"üîπ Length:\", len(data))\n",
        "\n",
        "\n",
        "if isinstance(data, list):\n",
        "    print(\"üîπ Keys in first entry:\", data[0].keys())\n",
        "    print(\"üîπ Example entry:\\n\", data[0])\n",
        "elif isinstance(data, dict):\n",
        "    first_key = list(data.keys())[0]\n",
        "    print(\"üîπ Keys in first entry:\", data[first_key].keys())\n",
        "    print(\"üîπ Example entry:\\n\", data[first_key])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWNHQV0j0l9I",
        "outputId": "f9fbdad9-72cd-40ce-a892-bc2143cb4394"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Type of JSON: <class 'list'>\n",
            "üîπ Length: 2806\n",
            "üîπ Keys in first entry: dict_keys(['audioFilename', 'text', 'gender', 'speaker'])\n",
            "üîπ Example entry:\n",
            " {'audioFilename': 'audios/844424931171856-711-f.wav', 'text': '‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂ ‡¶¨‡¶õ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶ï‡¶æ‡¶∞‡¶æ‡¶¶‡¶£‡ßç‡¶°', 'gender': 'female', 'speaker': '711'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, csv\n",
        "\n",
        "DATA_PATH = \"/content/dataset/Kathbath-Bengali-Test-Known\"\n",
        "json_path = os.path.join(DATA_PATH, \"data.json\")\n",
        "csv_path = os.path.join(DATA_PATH, \"metadata.csv\")\n",
        "\n",
        "\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Created metadata.csv\n",
        "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"utt_id\", \"audio_filepath\", \"transcript\", \"gender\", \"speaker\"])\n",
        "\n",
        "    for i, entry in enumerate(data):\n",
        "        audio_file = os.path.join(DATA_PATH, entry[\"audioFilename\"])\n",
        "        transcript = entry[\"text\"]\n",
        "        gender = entry[\"gender\"]\n",
        "        speaker = entry[\"speaker\"]\n",
        "        utt_id = f\"utt_{i:05d}\"\n",
        "        writer.writerow([utt_id, audio_file, transcript, gender, speaker])\n",
        "\n",
        "print(f\"‚úÖ metadata.csv created successfully ‚Üí {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU730XSW1KqO",
        "outputId": "6baaa7cf-1d20-4222-960b-53aecb8d1447"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ metadata.csv created successfully ‚Üí /content/dataset/Kathbath-Bengali-Test-Known/metadata.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "meta = pd.read_csv(csv_path)\n",
        "print(\"Rows:\", len(meta))\n",
        "meta.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "2BCo8Dj11jZ2",
        "outputId": "44ce110f-5045-4e51-f17e-ab286472fbfa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 2806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      utt_id                                     audio_filepath  \\\n",
              "0  utt_00000  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "1  utt_00001  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "2  utt_00002  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "3  utt_00003  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "4  utt_00004  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "\n",
              "                                          transcript  gender  speaker  \n",
              "0  ‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂...  female      711  \n",
              "1  ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßÅ‡¶ú‡¶® ‡¶ï‡ßç‡¶∞‡¶Æ‡¶∂ ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶¶‡ßÉ‡¶∂...  female      858  \n",
              "2  ‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡¶Æ‡¶∞‡ßç‡¶™‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶¶‡¶ø‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶® ‡¶∏‡¶ú‡ßç...  female      858  \n",
              "3  ‡¶¢‡¶æ‡¶ï‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶§‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßÅ‡¶≤ ‡¶™‡ßá‡¶Ø‡¶º‡ßá ‡¶∂‡¶ø‡¶∂‡ßÅ ‡¶ó‡ßÉ‡¶π‡¶ï‡¶∞‡ßç‡¶Æ...  female     1037  \n",
              "4  ‡¶™‡ßç‡¶∞‡¶ö‡ßç‡¶õ‡¶¶ ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶∂‡ßá‡¶∞‡¶™‡ßÅ‡¶∞‡ßá ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶Æ‡ßÄ‡¶≤‡ßÄ‡¶ó‡ßá‡¶∞ ‡¶Æ‡¶®‡ßã‡¶®‡¶Ø‡¶º‡¶® ‡¶™‡ßç...  female      428  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2170ae23-3b23-46c8-89fd-b48f754f61c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utt_id</th>\n",
              "      <th>audio_filepath</th>\n",
              "      <th>transcript</th>\n",
              "      <th>gender</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utt_00000</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂...</td>\n",
              "      <td>female</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utt_00001</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßÅ‡¶ú‡¶® ‡¶ï‡ßç‡¶∞‡¶Æ‡¶∂ ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶¶‡ßÉ‡¶∂...</td>\n",
              "      <td>female</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utt_00002</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡¶Æ‡¶∞‡ßç‡¶™‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶¶‡¶ø‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶® ‡¶∏‡¶ú‡ßç...</td>\n",
              "      <td>female</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utt_00003</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶¢‡¶æ‡¶ï‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶§‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßÅ‡¶≤ ‡¶™‡ßá‡¶Ø‡¶º‡ßá ‡¶∂‡¶ø‡¶∂‡ßÅ ‡¶ó‡ßÉ‡¶π‡¶ï‡¶∞‡ßç‡¶Æ...</td>\n",
              "      <td>female</td>\n",
              "      <td>1037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utt_00004</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶™‡ßç‡¶∞‡¶ö‡ßç‡¶õ‡¶¶ ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶∂‡ßá‡¶∞‡¶™‡ßÅ‡¶∞‡ßá ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶Æ‡ßÄ‡¶≤‡ßÄ‡¶ó‡ßá‡¶∞ ‡¶Æ‡¶®‡ßã‡¶®‡¶Ø‡¶º‡¶® ‡¶™‡ßç...</td>\n",
              "      <td>female</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2170ae23-3b23-46c8-89fd-b48f754f61c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2170ae23-3b23-46c8-89fd-b48f754f61c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2170ae23-3b23-46c8-89fd-b48f754f61c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-95838694-b048-4d3d-882c-a94e0784118c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95838694-b048-4d3d-882c-a94e0784118c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-95838694-b048-4d3d-882c-a94e0784118c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "meta",
              "summary": "{\n  \"name\": \"meta\",\n  \"rows\": 2806,\n  \"fields\": [\n    {\n      \"column\": \"utt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2806,\n        \"samples\": [\n          \"utt_02569\",\n          \"utt_02669\",\n          \"utt_01584\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2806,\n        \"samples\": [\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424931500977-99-m.wav\",\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424931107271-99-m.wav\",\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424930650938-278-m.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2805,\n        \"samples\": [\n          \"\\u0995\\u09bf\\u09a8\\u09cd\\u09a4\\u09c1 \\u0995\\u09cb\\u099a \\u09b9\\u09bf\\u09b8\\u09c7\\u09ac\\u09c7 \\u098f\\u09ac\\u09be\\u09b0\\u0987 \\u09aa\\u09cd\\u09b0\\u09a5\\u09ae \\u0987\\u0989\\u09b0\\u09cb\\u09aa\\u09c7 \\u0995\\u09be\\u099c \\u0995\\u09b0\\u09be\\u09b0 \\u09b8\\u09c1\\u09af\\u09cb\\u0997 \\u09aa\\u09be\\u099a\\u09cd\\u099b\\u09c7\\u09a8 \\u09ac\\u09be\\u0982\\u09b2\\u09be\\u09a6\\u09c7\\u09b6\\u09c7\\u09b0 \\u09ae\\u09b6\\u09bf\\u0989\\u09b0 \\u09b0\\u09b9\\u09ae\\u09be\\u09a8\",\n          \"\\u09b8\\u09cd\\u09ac\\u09be\\u09a7\\u09c0\\u09a8\\u09a4\\u09be\\u09a4\\u09cd\\u09a4\\u09cb\\u09b0 \\u09ad\\u09be\\u09b0\\u09a4\\u09c7\\u09b0 \\u09aa\\u09cd\\u09b0\\u09a5\\u09ae \\u09ad\\u09cb\\u099f\\u09a6\\u09be\\u09a4\\u09be \\u09ac\\u09bf\\u09b6\\u09cd\\u09ac\\u09c7\\u09b0 \\u09ac\\u09c3\\u09b9\\u09a4\\u09cd\\u09a4\\u09ae \\u0997\\u09a3\\u09a4\\u09a8\\u09cd\\u09a4\\u09cd\\u09b0\\u09c7\\u09b0 \\u09a8\\u09bf\\u09b0\\u09cd\\u09ac\\u09be\\u099a\\u09a8\\u09c7 \\u098f\\u09ac\\u09be\\u09b0\\u0993 \\u0985\\u0982\\u09b6 \\u09a8\\u09bf\\u09b2\\u09c7\\u09a8\",\n          \"\\u09ac\\u09bf\\u09a6\\u09c7\\u09b6\\u09bf\\u09b8\\u09b9 \\u09a4\\u09be\\u09ac\\u09b2\\u09bf\\u0997 \\u099c\\u09be\\u09ae\\u09be\\u09a4\\u09c7\\u09b0 \\u098f\\u0997\\u09be\\u09b0 \\u09b8\\u09a6\\u09b8\\u09cd\\u09af\\u0995\\u09c7 \\u0985\\u099c\\u09cd\\u099e\\u09be\\u09a8 \\u0995\\u09b0\\u09c7 \\u09ae\\u09be\\u09b2\\u09be\\u09ae\\u09be\\u09b2 \\u09b2\\u09c1\\u099f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 337,\n        \"min\": 99,\n        \"max\": 1175,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          711,\n          789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchaudio librosa soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7RuKMof1k3i",
        "outputId": "d7de3bab-fa33-4249-de08-52d0f4245994"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRIp5Cn08im8",
        "outputId": "e59ca304-1305-4889-ab74-3a95fb9dc2e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.0)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer) (3.14.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet torch torchvision torchaudio librosa soundfile jiwer tensorboard\n"
      ],
      "metadata": {
        "id": "bIe28AuloF0n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skkOkARNAedq",
        "outputId": "26971d71-bfa2-42ce-aab2-9e8c24d88ab4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, csv, math, random, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from jiwer import wer\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1BZYo2roKba",
        "outputId": "49072fe0-a90b-4319-e87a-219b2a83a453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, csv, math, random, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from jiwer import wer\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "DATA_PATH = \"/content/dataset/Kathbath-Bengali-Test-Known\"\n",
        "METADATA_CSV = os.path.join(DATA_PATH, \"metadata.csv\")\n",
        "MODEL_DIR = \"/content/models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTVabiO78v-i",
        "outputId": "49fb0dfb-44e0-4022-e8b8-49676d06ba51"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if not os.path.exists(METADATA_CSV):\n",
        "    json_path = os.path.join(DATA_PATH, \"data.json\")\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    with open(METADATA_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"utt_id\", \"audio_filepath\", \"transcript\", \"gender\", \"speaker\"])\n",
        "        for i, entry in enumerate(data):\n",
        "            audio_file = os.path.join(DATA_PATH, entry[\"audioFilename\"])\n",
        "            transcript = entry[\"text\"]\n",
        "            gender = entry.get(\"gender\", \"\")\n",
        "            speaker = entry.get(\"speaker\", \"\")\n",
        "            writer.writerow([f\"utt_{i:05d}\", audio_file, transcript, gender, speaker])\n",
        "    print(\"Wrote metadata.csv\")\n",
        "\n",
        "meta = pd.read_csv(METADATA_CSV)\n",
        "print(\"Total samples:\", len(meta))\n",
        "meta.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "tI7HFdo69M-c",
        "outputId": "bf0f3488-49e9-4eba-8e60-3a3aa3eebd1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 2806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      utt_id                                     audio_filepath  \\\n",
              "0  utt_00000  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "1  utt_00001  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "2  utt_00002  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "3  utt_00003  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "4  utt_00004  /content/dataset/Kathbath-Bengali-Test-Known/a...   \n",
              "\n",
              "                                          transcript  gender  speaker  \n",
              "0  ‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂...  female      711  \n",
              "1  ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßÅ‡¶ú‡¶® ‡¶ï‡ßç‡¶∞‡¶Æ‡¶∂ ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶¶‡ßÉ‡¶∂...  female      858  \n",
              "2  ‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡¶Æ‡¶∞‡ßç‡¶™‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶¶‡¶ø‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶® ‡¶∏‡¶ú‡ßç...  female      858  \n",
              "3  ‡¶¢‡¶æ‡¶ï‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶§‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßÅ‡¶≤ ‡¶™‡ßá‡¶Ø‡¶º‡ßá ‡¶∂‡¶ø‡¶∂‡ßÅ ‡¶ó‡ßÉ‡¶π‡¶ï‡¶∞‡ßç‡¶Æ...  female     1037  \n",
              "4  ‡¶™‡ßç‡¶∞‡¶ö‡ßç‡¶õ‡¶¶ ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶∂‡ßá‡¶∞‡¶™‡ßÅ‡¶∞‡ßá ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶Æ‡ßÄ‡¶≤‡ßÄ‡¶ó‡ßá‡¶∞ ‡¶Æ‡¶®‡ßã‡¶®‡¶Ø‡¶º‡¶® ‡¶™‡ßç...  female      428  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0705f07-5608-489d-b759-d626258ec49d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utt_id</th>\n",
              "      <th>audio_filepath</th>\n",
              "      <th>transcript</th>\n",
              "      <th>gender</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utt_00000</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂...</td>\n",
              "      <td>female</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utt_00001</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßÅ‡¶ú‡¶® ‡¶ï‡ßç‡¶∞‡¶Æ‡¶∂ ‡¶¶‡ßÇ‡¶∞‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶¶‡ßÉ‡¶∂...</td>\n",
              "      <td>female</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utt_00002</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡¶Æ‡¶∞‡ßç‡¶™‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶¶‡¶ø‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶® ‡¶∏‡¶ú‡ßç...</td>\n",
              "      <td>female</td>\n",
              "      <td>858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utt_00003</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶¢‡¶æ‡¶ï‡¶æ‡¶Ø‡¶º ‡¶≠‡¶æ‡¶§‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßÅ‡¶≤ ‡¶™‡ßá‡¶Ø‡¶º‡ßá ‡¶∂‡¶ø‡¶∂‡ßÅ ‡¶ó‡ßÉ‡¶π‡¶ï‡¶∞‡ßç‡¶Æ...</td>\n",
              "      <td>female</td>\n",
              "      <td>1037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utt_00004</td>\n",
              "      <td>/content/dataset/Kathbath-Bengali-Test-Known/a...</td>\n",
              "      <td>‡¶™‡ßç‡¶∞‡¶ö‡ßç‡¶õ‡¶¶ ‡¶ú‡¶æ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶∂‡ßá‡¶∞‡¶™‡ßÅ‡¶∞‡ßá ‡¶Ü‡¶ì‡¶Ø‡¶º‡¶æ‡¶Æ‡ßÄ‡¶≤‡ßÄ‡¶ó‡ßá‡¶∞ ‡¶Æ‡¶®‡ßã‡¶®‡¶Ø‡¶º‡¶® ‡¶™‡ßç...</td>\n",
              "      <td>female</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0705f07-5608-489d-b759-d626258ec49d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0705f07-5608-489d-b759-d626258ec49d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0705f07-5608-489d-b759-d626258ec49d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3003d500-4c87-485e-8106-514410fa660e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3003d500-4c87-485e-8106-514410fa660e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3003d500-4c87-485e-8106-514410fa660e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "meta",
              "summary": "{\n  \"name\": \"meta\",\n  \"rows\": 2806,\n  \"fields\": [\n    {\n      \"column\": \"utt_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2806,\n        \"samples\": [\n          \"utt_02569\",\n          \"utt_02669\",\n          \"utt_01584\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_filepath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2806,\n        \"samples\": [\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424931500977-99-m.wav\",\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424931107271-99-m.wav\",\n          \"/content/dataset/Kathbath-Bengali-Test-Known/audios/844424930650938-278-m.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2805,\n        \"samples\": [\n          \"\\u0995\\u09bf\\u09a8\\u09cd\\u09a4\\u09c1 \\u0995\\u09cb\\u099a \\u09b9\\u09bf\\u09b8\\u09c7\\u09ac\\u09c7 \\u098f\\u09ac\\u09be\\u09b0\\u0987 \\u09aa\\u09cd\\u09b0\\u09a5\\u09ae \\u0987\\u0989\\u09b0\\u09cb\\u09aa\\u09c7 \\u0995\\u09be\\u099c \\u0995\\u09b0\\u09be\\u09b0 \\u09b8\\u09c1\\u09af\\u09cb\\u0997 \\u09aa\\u09be\\u099a\\u09cd\\u099b\\u09c7\\u09a8 \\u09ac\\u09be\\u0982\\u09b2\\u09be\\u09a6\\u09c7\\u09b6\\u09c7\\u09b0 \\u09ae\\u09b6\\u09bf\\u0989\\u09b0 \\u09b0\\u09b9\\u09ae\\u09be\\u09a8\",\n          \"\\u09b8\\u09cd\\u09ac\\u09be\\u09a7\\u09c0\\u09a8\\u09a4\\u09be\\u09a4\\u09cd\\u09a4\\u09cb\\u09b0 \\u09ad\\u09be\\u09b0\\u09a4\\u09c7\\u09b0 \\u09aa\\u09cd\\u09b0\\u09a5\\u09ae \\u09ad\\u09cb\\u099f\\u09a6\\u09be\\u09a4\\u09be \\u09ac\\u09bf\\u09b6\\u09cd\\u09ac\\u09c7\\u09b0 \\u09ac\\u09c3\\u09b9\\u09a4\\u09cd\\u09a4\\u09ae \\u0997\\u09a3\\u09a4\\u09a8\\u09cd\\u09a4\\u09cd\\u09b0\\u09c7\\u09b0 \\u09a8\\u09bf\\u09b0\\u09cd\\u09ac\\u09be\\u099a\\u09a8\\u09c7 \\u098f\\u09ac\\u09be\\u09b0\\u0993 \\u0985\\u0982\\u09b6 \\u09a8\\u09bf\\u09b2\\u09c7\\u09a8\",\n          \"\\u09ac\\u09bf\\u09a6\\u09c7\\u09b6\\u09bf\\u09b8\\u09b9 \\u09a4\\u09be\\u09ac\\u09b2\\u09bf\\u0997 \\u099c\\u09be\\u09ae\\u09be\\u09a4\\u09c7\\u09b0 \\u098f\\u0997\\u09be\\u09b0 \\u09b8\\u09a6\\u09b8\\u09cd\\u09af\\u0995\\u09c7 \\u0985\\u099c\\u09cd\\u099e\\u09be\\u09a8 \\u0995\\u09b0\\u09c7 \\u09ae\\u09be\\u09b2\\u09be\\u09ae\\u09be\\u09b2 \\u09b2\\u09c1\\u099f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 337,\n        \"min\": 99,\n        \"max\": 1175,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          711,\n          789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_MELS = 80\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 256\n",
        "WIN_LENGTH = 1024\n",
        "\n",
        "def load_audio(path, sr=SAMPLE_RATE):\n",
        "    wav, orig_sr = sf.read(path)\n",
        "    if len(wav.shape) > 1:\n",
        "        wav = np.mean(wav, axis=1)\n",
        "    if orig_sr != sr:\n",
        "        wav = librosa.resample(wav.astype(np.float32), orig_sr, sr)\n",
        "    return wav.astype(np.float32)\n",
        "\n",
        "def compute_log_mel(wav):\n",
        "    mel = librosa.feature.melspectrogram(y=wav, sr=SAMPLE_RATE, n_fft=N_FFT,\n",
        "                                         hop_length=HOP_LENGTH, win_length=WIN_LENGTH, n_mels=N_MELS, power=1.0)\n",
        "    log_mel = librosa.power_to_db(mel)\n",
        "\n",
        "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-9)\n",
        "    return log_mel.astype(np.float32)\n",
        "\n",
        "class BengaliASRDataset(Dataset):\n",
        "    def __init__(self, metadata_df, max_duration=None):\n",
        "        self.df = metadata_df.reset_index(drop=True)\n",
        "        if max_duration:\n",
        "\n",
        "            pass\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        audio_path = row['audio_filepath']\n",
        "        transcript = str(row['transcript'])\n",
        "        wav = load_audio(audio_path)\n",
        "        feat = compute_log_mel(wav)\n",
        "\n",
        "        feat = torch.from_numpy(feat).unsqueeze(0)\n",
        "        target = torch.tensor(encode_text(transcript), dtype=torch.long)\n",
        "        return feat, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    feats = [b[0].squeeze(0).transpose(0,1) for b in batch]\n",
        "    feat_lens = torch.tensor([f.shape[0] for f in feats], dtype=torch.long)\n",
        "    feats_padded = pad_sequence(feats, batch_first=True)\n",
        "    feats_padded = feats_padded.transpose(1,2).unsqueeze(1)\n",
        "    targets = [b[1] for b in batch]\n",
        "    targets_concat = torch.cat(targets)\n",
        "    target_lens = torch.tensor([len(t) for t in targets], dtype=torch.long)\n",
        "    return feats_padded, feat_lens, torch.cat(targets), target_lens, targets\n"
      ],
      "metadata": {
        "id": "lG6EwQvo9VZO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BengaliASRDataset(meta.sample(frac=1.0).reset_index(drop=True))\n",
        "loader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn, num_workers=2)\n",
        "feats_padded, feat_lens, targets_concat, target_lens, targets_list = next(iter(loader))\n",
        "print(\"feats:\", feats_padded.shape, \"feat_lens:\", feat_lens, \"targets_concat_len:\", targets_concat.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7XmRe5S9XTW",
        "outputId": "e1498552-47d4-41af-f3e2-e55abbbdd030"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feats: torch.Size([4, 1, 80, 501]) feat_lens: tensor([366, 340, 286, 501]) targets_concat_len: torch.Size([242])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class CNNRNN_ASR(nn.Module):\n",
        "    def __init__(self, n_mels=80, cnn_channels=128, lstm_hidden=512, lstm_layers=2, n_classes=100):\n",
        "        super().__init__()\n",
        "        self.conv = ConvBlock(in_ch=1, out_ch=cnn_channels)\n",
        "\n",
        "        self.n_mels = n_mels\n",
        "        self.cnn_channels = cnn_channels\n",
        "        rep_size = (n_mels // 2) * cnn_channels\n",
        "        self.fc = nn.Linear(rep_size, lstm_hidden)\n",
        "        self.lstm = nn.LSTM(input_size=lstm_hidden, hidden_size=lstm_hidden, num_layers=lstm_layers,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.classifier = nn.Linear(lstm_hidden * 2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        B, Tprime, C, F = x.shape\n",
        "        x = x.reshape(B, Tprime, C * F)\n",
        "        x = self.fc(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.classifier(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        return x\n",
        "\n",
        "n_classes = len(vocab)\n",
        "model = CNNRNN_ASR(n_mels=N_MELS, cnn_channels=128, lstm_hidden=512, lstm_layers=2, n_classes=n_classes)\n",
        "model.to(device)\n",
        "print(\"Model params:\", sum(p.numel() for p in model.parameters())/1e6, \"M\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR9zRFQC9aDo",
        "outputId": "6e2f41bb-896a-4a3e-e3f2-2be47995913a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model params: 13.338047 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(meta, test_size=0.1, random_state=42, stratify=None)\n",
        "train_ds = BengaliASRDataset(train_df.reset_index(drop=True))\n",
        "val_ds = BengaliASRDataset(val_df.reset_index(drop=True))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "scaler = GradScaler()\n",
        "\n",
        "def greedy_decode(log_probs, input_lengths):\n",
        "\n",
        "    probs = torch.argmax(log_probs, dim=2)\n",
        "    T, B = probs.shape\n",
        "    out_texts = []\n",
        "    probs = probs.cpu().numpy().T\n",
        "    for b in range(B):\n",
        "        seq = probs[b].tolist()\n",
        "\n",
        "        prev = -1\n",
        "        chars = []\n",
        "        for p in seq:\n",
        "            if p != prev and p != 0:\n",
        "                chars.append(idx2char.get(p, \"\"))\n",
        "            prev = p\n",
        "        out_texts.append(\"\".join(chars))\n",
        "    return out_texts\n",
        "\n",
        "best_wer = 1.0\n",
        "EPOCHS = 12\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (feats_padded, feat_lens, targets_concat, target_lens, targets_list) in enumerate(train_loader):\n",
        "        feats_padded = feats_padded.to(device)\n",
        "\n",
        "        input_lengths = (feat_lens // 2).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            logits = model(feats_padded)\n",
        "            log_probs = F.log_softmax(logits, dim=2)\n",
        "\n",
        "            loss = ctc_loss(log_probs, targets_concat.to(device), input_lengths, target_lens.to(device))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        if (batch_idx+1) % 50 == 0:\n",
        "            print(f\"Epoch {epoch} Batch {batch_idx+1}: avg loss {running_loss/(batch_idx+1):.4f}\")\n",
        "    avg_train_loss = running_loss / (batch_idx+1)\n",
        "\n",
        "model.eval()\n",
        "all_refs, all_hyps = [], []\n",
        "with torch.no_grad():\n",
        "    for feats_padded, feat_lens_val, targets_concat_val, target_lens_val, targets_list_val in val_loader:\n",
        "        feats_padded = feats_padded.to(device)\n",
        "        input_lengths_val = (feat_lens_val // 2).to(device)\n",
        "        logits = model(feats_padded)\n",
        "        log_probs = F.log_softmax(logits, dim=2)\n",
        "\n",
        "        hyps = greedy_decode(log_probs, input_lengths_val)\n",
        "\n",
        "\n",
        "        for tgt in targets_list_val:\n",
        "            ref = \"\".join([idx2char[int(i)] for i in tgt.numpy().tolist() if int(i) != 0])\n",
        "            all_refs.append(ref)\n",
        "        all_hyps.extend(hyps)\n",
        "\n",
        "\n",
        "    computed_wer = wer(all_refs, all_hyps)\n",
        "    print(f\"Epoch {epoch} finished in {time.time()-t0:.1f}s ‚Äî TrainLoss: {avg_train_loss:.4f} ‚Äî Val WER: {computed_wer:.4f}\")\n",
        "\n",
        "    if computed_wer < best_wer:\n",
        "        best_wer = computed_wer\n",
        "        ckpt_path = os.path.join(MODEL_DIR, f\"best_asr_epoch{epoch}_wer{best_wer:.4f}.pt\")\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        print(\"Saved best model to\", ckpt_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sBmIMw_9mEb",
        "outputId": "0d7fc86b-d90e-4f30-861d-9546c7b629aa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1350547613.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-1350547613.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 50: avg loss 3.3542\n",
            "Epoch 1 Batch 100: avg loss 3.3534\n",
            "Epoch 1 Batch 150: avg loss 3.3509\n",
            "Epoch 1 Batch 200: avg loss 3.3466\n",
            "Epoch 1 Batch 250: avg loss 3.3316\n",
            "Epoch 1 Batch 300: avg loss 3.2634\n",
            "Epoch 2 Batch 50: avg loss 2.4235\n",
            "Epoch 2 Batch 100: avg loss 2.3186\n",
            "Epoch 2 Batch 150: avg loss 2.2233\n",
            "Epoch 2 Batch 200: avg loss 2.1505\n",
            "Epoch 2 Batch 250: avg loss 2.0855\n",
            "Epoch 2 Batch 300: avg loss 2.0206\n",
            "Epoch 3 Batch 50: avg loss 1.5783\n",
            "Epoch 3 Batch 100: avg loss 1.5523\n",
            "Epoch 3 Batch 150: avg loss 1.5316\n",
            "Epoch 3 Batch 200: avg loss 1.5102\n",
            "Epoch 3 Batch 250: avg loss 1.4881\n",
            "Epoch 3 Batch 300: avg loss 1.4694\n",
            "Epoch 4 Batch 50: avg loss 1.2541\n",
            "Epoch 4 Batch 100: avg loss 1.2396\n",
            "Epoch 4 Batch 150: avg loss 1.2355\n",
            "Epoch 4 Batch 200: avg loss 1.2282\n",
            "Epoch 4 Batch 250: avg loss 1.2145\n",
            "Epoch 4 Batch 300: avg loss 1.2061\n",
            "Epoch 5 Batch 50: avg loss 1.0653\n",
            "Epoch 5 Batch 100: avg loss 1.0559\n",
            "Epoch 5 Batch 150: avg loss 1.0415\n",
            "Epoch 5 Batch 200: avg loss 1.0467\n",
            "Epoch 5 Batch 250: avg loss 1.0371\n",
            "Epoch 5 Batch 300: avg loss 1.0309\n",
            "Epoch 6 Batch 50: avg loss 0.9130\n",
            "Epoch 6 Batch 100: avg loss 0.9071\n",
            "Epoch 6 Batch 150: avg loss 0.9056\n",
            "Epoch 6 Batch 200: avg loss 0.9000\n",
            "Epoch 6 Batch 250: avg loss 0.9047\n",
            "Epoch 6 Batch 300: avg loss 0.9025\n",
            "Epoch 7 Batch 50: avg loss 0.7978\n",
            "Epoch 7 Batch 100: avg loss 0.7906\n",
            "Epoch 7 Batch 150: avg loss 0.7976\n",
            "Epoch 7 Batch 200: avg loss 0.7940\n",
            "Epoch 7 Batch 250: avg loss 0.7884\n",
            "Epoch 7 Batch 300: avg loss 0.7872\n",
            "Epoch 8 Batch 50: avg loss 0.6842\n",
            "Epoch 8 Batch 100: avg loss 0.6787\n",
            "Epoch 8 Batch 150: avg loss 0.6813\n",
            "Epoch 8 Batch 200: avg loss 0.6790\n",
            "Epoch 8 Batch 250: avg loss 0.6808\n",
            "Epoch 8 Batch 300: avg loss 0.6834\n",
            "Epoch 9 Batch 50: avg loss 0.5430\n",
            "Epoch 9 Batch 100: avg loss 0.5536\n",
            "Epoch 9 Batch 150: avg loss 0.5703\n",
            "Epoch 9 Batch 200: avg loss 0.5803\n",
            "Epoch 9 Batch 250: avg loss 0.5817\n",
            "Epoch 9 Batch 300: avg loss 0.5859\n",
            "Epoch 10 Batch 50: avg loss 0.4820\n",
            "Epoch 10 Batch 100: avg loss 0.4879\n",
            "Epoch 10 Batch 150: avg loss 0.4913\n",
            "Epoch 10 Batch 200: avg loss 0.4949\n",
            "Epoch 10 Batch 250: avg loss 0.4985\n",
            "Epoch 10 Batch 300: avg loss 0.5004\n",
            "Epoch 11 Batch 50: avg loss 0.3948\n",
            "Epoch 11 Batch 100: avg loss 0.4019\n",
            "Epoch 11 Batch 150: avg loss 0.4016\n",
            "Epoch 11 Batch 200: avg loss 0.4043\n",
            "Epoch 11 Batch 250: avg loss 0.4038\n",
            "Epoch 11 Batch 300: avg loss 0.4111\n",
            "Epoch 12 Batch 50: avg loss 0.3125\n",
            "Epoch 12 Batch 100: avg loss 0.3195\n",
            "Epoch 12 Batch 150: avg loss 0.3304\n",
            "Epoch 12 Batch 200: avg loss 0.3305\n",
            "Epoch 12 Batch 250: avg loss 0.3372\n",
            "Epoch 12 Batch 300: avg loss 0.3371\n",
            "Epoch 12 finished in 70.7s ‚Äî TrainLoss: 0.3378 ‚Äî Val WER: 0.7843\n",
            "Saved best model to /content/models/best_asr_epoch12_wer0.7843.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_text = \" \".join(meta['transcript'].astype(str).tolist())\n",
        "chars = sorted(list(set(all_text)))\n",
        "\n",
        "vocab = [\"<blank>\"] + chars\n",
        "char2idx = {c:i for i,c in enumerate(vocab)}\n",
        "idx2char = {i:c for c,i in char2idx.items()}\n",
        "\n",
        "print(\"Vocab size (including blank):\", len(vocab))\n",
        "print(\"Example tokens:\", list(vocab)[:30])\n",
        "\n",
        "def encode_text(text):\n",
        "\n",
        "    return [char2idx.get(ch, 0) for ch in text]\n",
        "\n",
        "def decode_indices(indices):\n",
        "\n",
        "    s = []\n",
        "    prev = None\n",
        "    for idx in indices:\n",
        "        if idx != prev and idx != 0:\n",
        "            s.append(idx2char.get(idx, \"\"))\n",
        "        prev = idx\n",
        "    return \"\".join(s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeBSopU69R8X",
        "outputId": "772d6f69-0ce5-4735-be37-dc487fcda95d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size (including blank): 63\n",
            "Example tokens: ['<blank>', ' ', '‡•§', '‡¶Å', '‡¶Ç', '‡¶É', '‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û', '‡¶ü', '‡¶†', '‡¶°', '‡¶¢']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load(\"/content/models/best_asr_epoch12_wer0.7843.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "def transcribe_file(audio_path):\n",
        "    wav, sr = sf.read(audio_path)\n",
        "    if sr != 16000:\n",
        "        wav = librosa.resample(wav.astype(np.float32), orig_sr=sr, target_sr=16000)\n",
        "    feat = compute_log_mel(wav)\n",
        "    x = torch.from_numpy(feat).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        log_probs = F.log_softmax(logits, dim=2)\n",
        "        preds = torch.argmax(log_probs, dim=2).squeeze(1).cpu().numpy().tolist()\n",
        "    return decode_indices(preds)\n",
        "\n",
        "\n",
        "sample_path = meta.iloc[10][\"audio_filepath\"]\n",
        "print(\" Reference:\", meta.iloc[10][\"transcript\"])\n",
        "print(\" Predicted:\", transcribe_file(sample_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImL7ouFSodkf",
        "outputId": "c4bf2490-bc47-4865-acd7-7475b79e12f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéß Reference: ‡¶ó‡¶§ ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶ú‡¶æ‡¶®‡ßÅ‡¶Ø‡¶º‡¶æ‡¶∞‡¶ø ‡¶∏‡¶ï‡¶æ‡¶≤‡ßá ‡¶ö‡¶ü‡ßç‡¶ü‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ ‡¶Æ‡¶π‡¶æ‡¶®‡¶ó‡¶∞‡ßá‡¶∞ ‡¶ö‡¶æ‡¶®‡ßç‡¶¶‡¶ó‡¶æ‡¶Å‡¶ì ‡¶Ü‡¶¨‡¶æ‡¶∏‡¶ø‡¶ï ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º ‡¶°‡¶æ\n",
            "üó£Ô∏è Predicted: ‡¶ó‡¶§ ‡¶è‡¶ï‡¶§‡ßç‡¶∞‡¶ø‡¶∂ ‡¶ú‡¶æ‡¶®‡ßÅ‡¶Ø‡¶º‡¶æ‡¶∞‡¶ø ‡¶∏‡¶æ‡¶ï‡¶æ‡¶≤‡ßá ‡¶ö‡¶ü‡ßç‡¶ü‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ ‡¶Æ‡¶π‡¶æ‡¶®‡¶ó‡¶∞‡ßá‡¶∞ ‡¶ö‡¶æ‡¶®‡ßç‡¶¶‡¶ó‡¶æ‡¶Å‡¶ì ‡¶Ü‡¶¨‡¶æ‡¶∏‡¶ø‡¶ï ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º ‡¶°‡¶æ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "example = torch.randn(1,1,N_MELS,300).to(device)\n",
        "traced = torch.jit.trace(model.to('cpu'), example.cpu())\n",
        "torch.jit.save(traced, \"/content/models/asr_cnnrnn_torchscript.pt\")\n",
        "print(\" TorchScript model saved for deployment!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XSVZAcrtwX9",
        "outputId": "75c657f7-7aa1-4997-80ed-1f310401bf3e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TorchScript model saved for deployment!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.jit.load(\"/content/models/asr_cnnrnn_torchscript.pt\", map_location=device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Force all submodules to device\n",
        "for name, module in model.named_modules():\n",
        "    for param in module.parameters(recurse=False):\n",
        "        param.data = param.data.to(device)\n",
        "    for buffer in module.buffers(recurse=False):\n",
        "        buffer.data = buffer.data.to(device)\n",
        "\n",
        "print(f\" Model and all LSTM weights moved to: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8rpIom4xbzz",
        "outputId": "7aa51bad-434e-437c-d1e8-0c250f493dac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model and all LSTM weights moved to: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, librosa, soundfile as sf, torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.jit.load(\"/content/models/asr_cnnrnn_torchscript.pt\", map_location=device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    for param in module.parameters(recurse=False):\n",
        "        param.data = param.data.to(device)\n",
        "    for buffer in module.buffers(recurse=False):\n",
        "        buffer.data = buffer.data.to(device)\n",
        "\n",
        "print(f\" Model loaded and synced on: {device}\")\n",
        "\n",
        "def transcribe_file(audio_path):\n",
        "    wav, sr = sf.read(audio_path)\n",
        "    if len(wav.shape) > 1:\n",
        "        wav = np.mean(wav, axis=1)\n",
        "    if sr != 16000:\n",
        "        wav = librosa.resample(wav.astype(np.float32), orig_sr=sr, target_sr=16000)\n",
        "    feat = compute_log_mel(wav)\n",
        "    x = torch.from_numpy(feat).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        log_probs = F.log_softmax(logits, dim=2)\n",
        "        preds = torch.argmax(log_probs, dim=2).squeeze(1).cpu().numpy().tolist()\n",
        "    return decode_indices(preds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM1Bb0CvzDsG",
        "outputId": "bd9f3adb-9e48-477a-cd24-e45f33e39ec6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded and synced on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "scripted = torch.jit.script(model)\n",
        "torch.jit.save(scripted, \"/content/models/asr_cnnrnn_torchscript.pt\")\n",
        "print(\" Scripted model saved without device lock\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydnLJSr9vqvk",
        "outputId": "be9898de-1159-4e28-8b1f-d33e0254ee53"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scripted model saved without device lock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.jit.load(\"/content/models/asr_cnnrnn_torchscript.pt\", map_location=device)\n",
        "model.to(device).eval()\n",
        "print(\"‚úÖ Scripted model loaded on\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esnp3bxC0g2f",
        "outputId": "988a0267-aee6-43b1-a874-72997e02e7b5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scripted model loaded on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "scripted = torch.jit.script(model)\n",
        "torch.jit.save(scripted, \"/content/models/asr_cnnrnn_torchscript.pt\")\n"
      ],
      "metadata": {
        "id": "aE8Lm4pn0klS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "scripted = torch.jit.script(model)\n",
        "torch.jit.save(scripted, \"/content/models/asr_cnnrnn_scripted_fixed.pt\")\n",
        "\n",
        "print(\"‚úÖ Saved SCRIPTED model at /content/models/asr_cnnrnn_scripted_fixed.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_unz4DYn1WF3",
        "outputId": "069712ad-c067-4eb7-dd6c-d47d5110379a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved SCRIPTED model at /content/models/asr_cnnrnn_scripted_fixed.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your trained model (TorchScript preferred)\n",
        "\n",
        "\n",
        "import torch, torch.nn.functional as F\n",
        "import numpy as np, librosa, soundfile as sf\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Using device:\", device)\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/content/models/asr_cnnrnn_scripted_fixed.pt\"\n",
        "\n",
        "model = torch.jit.load(MODEL_PATH, map_location=device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Scripted model loaded successfully on\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTIxPU5V2qkz",
        "outputId": "5a34c284-c33b-4e05-c3f6-2f60416d9d02"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n",
            "‚úÖ Scripted model loaded successfully on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "scripted = torch.jit.script(model)\n",
        "torch.jit.save(scripted, \"/content/models/asr_cnnrnn_scripted_fixed.pt\")\n",
        "\n",
        "print(\"‚úÖ Scripted model saved at /content/models/asr_cnnrnn_scripted_fixed.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oE44eT93NmH",
        "outputId": "88ca7b95-5d49-4ef7-8bf7-a6ebf9f979ed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Scripted model saved at /content/models/asr_cnnrnn_scripted_fixed.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#   Fixed model-loading cell  (uses SCRIPTED model)\n",
        "\n",
        "import torch, torch.nn.functional as F\n",
        "import numpy as np, librosa, soundfile as sf\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Using device:\", device)\n",
        "\n",
        "MODEL_PATH = \"/content/models/asr_cnnrnn_scripted_fixed.pt\"   # <-- new scripted model\n",
        "\n",
        "model = torch.jit.load(MODEL_PATH, map_location=device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"‚úÖ Scripted model loaded successfully on\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HGpkwCJ3Px7",
        "outputId": "a80aaf29-4c86-4c44-d974-a6ddcb4cb76c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n",
            "‚úÖ Scripted model loaded successfully on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = meta.iloc[0][\"audio_filepath\"]\n",
        "print(\"Ref:\", meta.iloc[0][\"transcript\"])\n",
        "print(\"Pred:\", transcribe_file(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PqrRz9w1LYB",
        "outputId": "0ed1fe47-8c60-49bb-ee00-c3dd576347e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ref: ‡¶∂‡ßá‡¶ñ ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ‡¶ï‡ßá ‡¶π‡¶§‡ßç‡¶Ø‡¶æ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ó‡¶æ‡¶∞ ‡¶ú‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∂ ‡¶¨‡¶õ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶ï‡¶æ‡¶∞‡¶æ‡¶¶‡¶£‡ßç‡¶°\n",
            "Pred: ‚ùå Error during transcription: The following operation failed in the TorchScript interpreter.\n",
            "Traceback of TorchScript, serialized code (most recent call last):\n",
            "  File \"code/__torch__.py\", line 24, in forward\n",
            "    F = ops.prim.NumToTensor(torch.size(x0, 3))\n",
            "    input = torch.reshape(x0, [_0, _1, int(torch.mul(C, F))])\n",
            "    _2 = (lstm).forward((fc).forward(input, ), )\n",
            "          ~~~~~~~~~~~~~ <--- HERE\n",
            "    _3 = torch.permute((classifier).forward(_2, ), [1, 0, 2])\n",
            "    return _3\n",
            "  File \"code/__torch__/torch/nn/modules/rnn.py\", line 46, in forward\n",
            "    _1 = [hx, hx0]\n",
            "    _2 = [weight_ih_l0, weight_hh_l0, bias_ih_l0, bias_hh_l0, weight_ih_l0_reverse, weight_hh_l0_reverse, bias_ih_l0_reverse, bias_hh_l0_reverse, weight_ih_l1, weight_hh_l1, bias_ih_l1, bias_hh_l1, weight_ih_l1_reverse, weight_hh_l1_reverse, bias_ih_l1_reverse, bias_hh_l1_reverse]\n",
            "    input, _3, _4 = torch.lstm(argument_1, _1, _2, True, 2, 0., False, True, True)\n",
            "                    ~~~~~~~~~~ <--- HERE\n",
            "    return input\n",
            "\n",
            "Traceback of TorchScript, original code (most recent call last):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py(1124): forward\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1763): _slow_forward\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1784): _call_impl\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1773): _wrapped_call_impl\n",
            "/tmp/ipython-input-638399730.py(35): forward\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1763): _slow_forward\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1784): _call_impl\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py(1773): _wrapped_call_impl\n",
            "/usr/local/lib/python3.12/dist-packages/torch/jit/_trace.py(1282): trace_module\n",
            "/usr/local/lib/python3.12/dist-packages/torch/jit/_trace.py(696): _trace_impl\n",
            "/usr/local/lib/python3.12/dist-packages/torch/jit/_trace.py(1002): trace\n",
            "/tmp/ipython-input-2589018509.py(3): <cell line: 0>\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py(528): run_cell\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py(383): do_execute\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py(730): execute_request\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py(499): process_one\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\n",
            "/usr/lib/python3.12/asyncio/events.py(88): _run\n",
            "/usr/lib/python3.12/asyncio/base_events.py(1999): _run_once\n",
            "/usr/lib/python3.12/asyncio/base_events.py(645): run_forever\n",
            "/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py(211): start\n",
            "/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py(712): start\n",
            "/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py(992): launch_instance\n",
            "/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py(37): <module>\n",
            "<frozen runpy>(88): _run_code\n",
            "<frozen runpy>(198): _run_module_as_main\n",
            "RuntimeError: Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Bengali Speech-to-Text Web App  (CNN-RNN Hybrid)\n",
        "# Safe for GPU, works in Google Colab\n",
        "\n",
        "\n",
        "!pip install --quiet gradio torch torchvision torchaudio librosa soundfile jiwer\n",
        "\n",
        "import gradio as gr\n",
        "import torch, numpy as np, librosa, soundfile as sf, torch.nn.functional as F\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Using device:\", device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    for param in module.parameters(recurse=False):\n",
        "        param.data = param.data.to(device)\n",
        "    for buffer in module.buffers(recurse=False):\n",
        "        buffer.data = buffer.data.to(device)\n",
        "\n",
        "print(f\"‚úÖ Model loaded & synced on {device}\")\n",
        "\n",
        "\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_MELS = 80\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 256\n",
        "WIN_LENGTH = 1024\n",
        "\n",
        "def compute_log_mel(wav):\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=wav, sr=SAMPLE_RATE, n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH, win_length=WIN_LENGTH,\n",
        "        n_mels=N_MELS, power=1.0\n",
        "    )\n",
        "    log_mel = librosa.power_to_db(mel)\n",
        "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-9)\n",
        "    return log_mel.astype(np.float32)\n",
        "\n",
        "\n",
        "def decode_indices(indices):\n",
        "    s, prev = [], None\n",
        "    for idx in indices:\n",
        "        if idx != prev and idx != 0:\n",
        "            s.append(idx2char.get(idx, \"\"))\n",
        "        prev = idx\n",
        "    return \"\".join(s)\n",
        "\n",
        "\n",
        "def transcribe_file(audio_path):\n",
        "    try:\n",
        "        wav, sr = sf.read(audio_path)\n",
        "        if len(wav.shape) > 1:\n",
        "            wav = np.mean(wav, axis=1)\n",
        "        if sr != SAMPLE_RATE:\n",
        "            wav = librosa.resample(wav.astype(np.float32), orig_sr=sr, target_sr=SAMPLE_RATE)\n",
        "\n",
        "        feat = compute_log_mel(wav)\n",
        "        x = torch.from_numpy(feat).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            log_probs = F.log_softmax(logits, dim=2)\n",
        "            preds = torch.argmax(log_probs, dim=2).squeeze(1).cpu().numpy().tolist()\n",
        "\n",
        "        text = decode_indices(preds)\n",
        "        return text or \"‚ö†Ô∏è Could not decode (try clearer/longer audio).\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error during transcription: {e}\"\n",
        "\n",
        "\n",
        "def transcribe_gradio(audio):\n",
        "    return transcribe_file(audio)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=transcribe_gradio,\n",
        "    inputs=gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"üéôÔ∏è Speak or upload Bengali audio\"),\n",
        "    outputs=gr.Textbox(label=\"üìù Transcribed Text\"),\n",
        "    title=\"üáßüá© Bengali Speech-to-Text (CNN-RNN Hybrid)\",\n",
        "    description=\"Deep-learning Speech-to-Text system trained on Bhashini Bengali corpus using CNN + BiLSTM + CTC.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y1GlvoN3t1CH",
        "outputId": "b3e2bc61-cc85-459a-ca30-6757f3a86c4a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n",
            "‚úÖ Model loaded & synced on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2a04b26739920d91dc.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2a04b26739920d91dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://2a04b26739920d91dc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install --quiet gradio torch torchvision torchaudio librosa soundfile jiwer\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np, librosa, soundfile as sf, gradio as gr\n",
        "import os\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"‚úÖ Using device:\", device)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.pool = nn.MaxPool2d((2,2))\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class CNNRNN_ASR(nn.Module):\n",
        "    def __init__(self, n_mels=80, cnn_channels=128, lstm_hidden=512, lstm_layers=2, n_classes=100):\n",
        "        super().__init__()\n",
        "        self.conv = ConvBlock(1, cnn_channels)\n",
        "        rep_size = (n_mels // 2) * cnn_channels\n",
        "        self.fc = nn.Linear(rep_size, lstm_hidden)\n",
        "        self.lstm = nn.LSTM(lstm_hidden, lstm_hidden, lstm_layers,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.classifier = nn.Linear(lstm_hidden * 2, n_classes)\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = x.permute(0,3,1,2).reshape(x.size(0), x.size(3), -1)\n",
        "        x = self.fc(x)\n",
        "        h0 = torch.zeros(self.lstm.num_layers * 2, x.size(0), self.lstm.hidden_size, device=x.device)\n",
        "        c0 = torch.zeros_like(h0)\n",
        "        x, _ = self.lstm(x, (h0, c0))\n",
        "        x = self.classifier(x)\n",
        "        x = x.permute(1,0,2)\n",
        "        return x\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/content/models/best_asr_epoch12_wer0.7843.pt\"\n",
        "\n",
        "\n",
        "try:\n",
        "    len(vocab)\n",
        "except NameError:\n",
        "    meta = pd.read_csv(\"/content/dataset/Kathbath-Bengali-Test-Known/metadata.csv\")\n",
        "    all_text = \" \".join(meta['transcript'].astype(str).tolist())\n",
        "    chars = sorted(list(set(all_text)))\n",
        "    vocab = [\"<blank>\"] + chars\n",
        "    char2idx = {c:i for i,c in enumerate(vocab)}\n",
        "    idx2char = {i:c for c,i in char2idx.items()}\n",
        "    print(\"‚úÖ Vocab rebuilt with size:\", len(vocab))\n",
        "\n",
        "model = CNNRNN_ASR(n_mels=80, cnn_channels=128, lstm_hidden=512,\n",
        "                   lstm_layers=2, n_classes=len(vocab))\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.to(device).eval()\n",
        "print(\"‚úÖ Model loaded successfully from checkpoint!\")\n",
        "\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_MELS = 80\n",
        "N_FFT = 1024\n",
        "HOP_LENGTH = 256\n",
        "WIN_LENGTH = 1024\n",
        "\n",
        "def compute_log_mel(wav):\n",
        "    mel = librosa.feature.melspectrogram(y=wav, sr=SAMPLE_RATE, n_fft=N_FFT,\n",
        "                                         hop_length=HOP_LENGTH, win_length=WIN_LENGTH,\n",
        "                                         n_mels=N_MELS, power=1.0)\n",
        "    log_mel = librosa.power_to_db(mel)\n",
        "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-9)\n",
        "    return log_mel.astype(np.float32)\n",
        "\n",
        "def decode_indices(indices):\n",
        "    s, prev = [], None\n",
        "    for idx in indices:\n",
        "        if idx != prev and idx != 0:\n",
        "            s.append(idx2char.get(idx, \"\"))\n",
        "        prev = idx\n",
        "    return \"\".join(s)\n",
        "\n",
        "\n",
        "def transcribe_file(audio_path):\n",
        "    try:\n",
        "        wav, sr = sf.read(audio_path)\n",
        "        if len(wav.shape) > 1: wav = np.mean(wav, axis=1)\n",
        "        if sr != SAMPLE_RATE:\n",
        "            wav = librosa.resample(wav.astype(np.float32), orig_sr=sr, target_sr=SAMPLE_RATE)\n",
        "        feat = compute_log_mel(wav)\n",
        "        x = torch.from_numpy(feat).unsqueeze(0).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            log_probs = F.log_softmax(logits, dim=2)\n",
        "            preds = torch.argmax(log_probs, dim=2).squeeze(1).cpu().numpy().tolist()\n",
        "        text = decode_indices(preds)\n",
        "        return text or \"‚ö†Ô∏è Could not decode (try clearer/longer audio).\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error during transcription: {e}\"\n",
        "\n",
        "\n",
        "def transcribe_gradio(audio):\n",
        "    return transcribe_file(audio)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=transcribe_gradio,\n",
        "    inputs=gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"üéôÔ∏è Speak or upload Bengali audio\"),\n",
        "    outputs=gr.Textbox(label=\"üìù Transcribed Text\"),\n",
        "    title=\"üáßüá© Bengali Speech-to-Text (CNN-RNN Hybrid Deep Model)\",\n",
        "    description=\"Speech-to-Text model trained on Bhashini Bengali corpus using CNN+BiLSTM+CTC. GPU-safe & permanent version.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RCyI0cZr0omQ",
        "outputId": "39374585-2e01-41b4-aaeb-f92cec19e44b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Using device: cuda\n",
            "‚úÖ Model loaded successfully from checkpoint!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6e4f7062c2356a21da.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6e4f7062c2356a21da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://6e4f7062c2356a21da.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Bengali Speech ‚Üí Hindi Text (No Conflicts Version)\n",
        "\n",
        "\n",
        "!pip install --quiet deep-translator\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def transcribe_gradio(audio):\n",
        "    bengali_text = transcribe_file(audio)\n",
        "    if bengali_text.startswith(\"‚ùå\"):\n",
        "        return bengali_text\n",
        "    try:\n",
        "        translated = GoogleTranslator(source='bn', target='hi').translate(bengali_text)\n",
        "        return f\"üó£Ô∏è Bengali: {bengali_text}\\nüáÆüá≥ Hindi: {translated}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Translation failed: {e}\\nBengali text: {bengali_text}\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=transcribe_gradio,\n",
        "    inputs=gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"üéôÔ∏è Speak or upload Bengali audio\"),\n",
        "    outputs=gr.Textbox(label=\"üìù Hindi Transcription\"),\n",
        "    title=\"üéß Bengali Speech ‚Üí Hindi Text Translator\",\n",
        "    description=\"CNN‚ÄìRNN Speech-to-Text for Bengali + automatic Hindi translation (deep-translator)\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOMlBO3M3wcr",
        "outputId": "507ba0b3-c558-44e0-d6b3-8bf2a9027956"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2957271a882fcf3ac9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2957271a882fcf3ac9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 124, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 110, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 390, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 289, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7b7d48514b90 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://2957271a882fcf3ac9.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uc48MMcC_AX4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}